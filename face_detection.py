import cv2
import numpy as np
import mediapipe as mp  # ê°€ë³ê³  ë¹ ë¥¸ ì–¼êµ´ ê²€ì¶œ ë¼ì´ë¸ŒëŸ¬ë¦¬
from pyk4a import PyK4A, Config, ColorResolution, DepthMode, FPS

# â”€â”€â”€ [ì„¤ì •: ê±°ë¦¬ í•„í„°ë§ ë²”ìœ„] â”€â”€â”€
MIN_DISTANCE = 0.3   # m
MAX_DISTANCE = 0.5   # m

# â”€â”€â”€ [ì„¤ì •: ì•ˆí‹° ìŠ¤í‘¸í•‘(ì‹¤ë¬¼ vs ì‚¬ì§„) ì„ê³„ê°’] â”€â”€â”€
# ì–¼êµ´ ê¹Šì´ íŒ¨ì¹˜ì˜ í‘œì¤€í¸ì°¨ê°€ ì´ ê°’ë³´ë‹¤ ì‘ìœ¼ë©´ "í‰ë©´(ì‚¬ì§„/ëª¨ë‹ˆí„°)"ì¼ ê°€ëŠ¥ì„±ì´ ë†’ë‹¤ê³  ê°„ì£¼
DEPTH_STD_THRESHOLD_MM = 15.0    # 15mm (í™˜ê²½ì— ë”°ë¼ íŠœë‹ í•„ìš”)
MIN_VALID_DEPTH_PIXELS = 80      # ìµœì†Œ ìœ íš¨ ê¹Šì´ í”½ì…€ ìˆ˜ (ë„ˆë¬´ ì ìœ¼ë©´ ì‹ ë¢°ë„ ë‚®ìŒ)

# 1. ë¯¸ë””ì–´íŒŒì´í”„(ì–¼êµ´ ê²€ì¶œ AI) ì´ˆê¸°í™”
mp_face_detection = mp.solutions.face_detection
face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.6)

def main():
    # 2. Azure Kinect ì¹´ë©”ë¼ ì„¤ì •
    k4a = PyK4A(
        Config(
            color_resolution=ColorResolution.RES_720P,
            depth_mode=DepthMode.NFOV_UNBINNED,
            camera_fps=FPS.FPS_30,
            synchronized_images_only=True,
        )
    )
    
    try:
        k4a.start()
        print(f"âœ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ (ë©€í‹° ì–¼êµ´ + ì•ˆí‹°ìŠ¤í‘¸í•‘ ë²„ì „)")
        print(f"ğŸ¯ ìœ íš¨ ê±°ë¦¬ ì„¤ì •: {MIN_DISTANCE}m ~ {MAX_DISTANCE}m")
        print(f"ğŸ›¡ ì•ˆí‹°ìŠ¤í‘¸í•‘ ê¹Šì´ í‘œì¤€í¸ì°¨ ì„ê³„ê°’: {DEPTH_STD_THRESHOLD_MM} mm")
    except Exception as e:
        print(f"âŒ ì¹´ë©”ë¼ ì—°ê²° ì‹¤íŒ¨: {e}")
        return

    # ì¢Œí‘œ ê³„ì‚°ìš© íŒŒë¼ë¯¸í„° (color ì¹´ë©”ë¼ ë‚´ì°¸ìˆ˜)
    intrinsics = k4a.calibration.get_camera_matrix(1)
    fx, fy = intrinsics[0, 0], intrinsics[1, 1]
    cx, cy = intrinsics[0, 2], intrinsics[1, 2]

    while True:
        capture = k4a.get_capture()
        
        if capture.color is not None and capture.depth is not None:
            # 1. ì´ë¯¸ì§€ ì²˜ë¦¬ (MediaPipeëŠ” RGBë¥¼ ì‚¬ìš©)
            img_bgr = capture.color[:, :, :3].copy()  # ì“°ê¸° ê°€ëŠ¥í•˜ë„ë¡ ë³µì‚¬
            img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
            
            # 2. Depth ë§µ (ì´ë¯¸ colorì— ì •ë ¬ëœ ê¹Šì´)
            transformed_depth = capture.transformed_depth

            # 3. ì–¼êµ´ ê²€ì¶œ ìˆ˜í–‰
            results = face_detection.process(img_rgb)

            best_face = None  # ê°€ì¥ ê°€ê¹Œìš´ ì–¼êµ´ ì •ë³´ ì €ì¥ìš©

            if results.detections:
                h, w, _ = img_bgr.shape

                for detection in results.detections:
                    # â”€â”€â”€ [A] Bounding Box ì¢Œí‘œ ê³„ì‚° â”€â”€â”€
                    bboxC = detection.location_data.relative_bounding_box
                    x = int(bboxC.xmin * w)
                    y = int(bboxC.ymin * h)
                    box_w = int(bboxC.width * w)
                    box_h = int(bboxC.height * h)

                    # ë°•ìŠ¤ ì˜ì—­ í´ë¨í•‘ (í™”ë©´ ë°–ìœ¼ë¡œ ë‚˜ê°€ëŠ” ê²½ìš° ëŒ€ë¹„)
                    x1 = max(0, x)
                    y1 = max(0, y)
                    x2 = min(w - 1, x + box_w)
                    y2 = min(h - 1, y + box_h)

                    if x2 <= x1 or y2 <= y1:
                        continue  # ì˜ëª»ëœ ë°•ìŠ¤

                    # â”€â”€â”€ [B] ì¤‘ì‹¬ì  ê³„ì‚° â”€â”€â”€
                    center_x = (x1 + x2) // 2
                    center_y = (y1 + y2) // 2

                    # â”€â”€â”€ [C] ê¹Šì´ íŒ¨ì¹˜ ì¶”ì¶œ (ì–¼êµ´ ë°•ìŠ¤ ì¤‘ì•™ ë¶€ë¶„ë§Œ ì‚¬ìš©) â”€â”€â”€
                    # ì–¼êµ´ ë°•ìŠ¤ì˜ ì¤‘ì•™ 40% ì˜ì—­ ì‚¬ìš©
                    patch_w = int((x2 - x1) * 0.4)
                    patch_h = int((y2 - y1) * 0.4)

                    patch_cx = center_x
                    patch_cy = center_y

                    px1 = max(0, patch_cx - patch_w // 2)
                    px2 = min(w - 1, patch_cx + patch_w // 2)
                    py1 = max(0, patch_cy - patch_h // 2)
                    py2 = min(h - 1, patch_cy + patch_h // 2)

                    if px2 <= px1 or py2 <= py1:
                        continue

                    depth_patch = transformed_depth[py1:py2+1, px1:px2+1]
                    valid_depth = depth_patch[depth_patch > 0]  # 0ì€ ë¯¸ì¸¡ì •ê°’ì´ë¯€ë¡œ ì œì™¸

                    if valid_depth.size < MIN_VALID_DEPTH_PIXELS:
                        # ìœ íš¨ ê¹Šì´ í”½ì…€ ë„ˆë¬´ ì ìœ¼ë©´ ì‹ ë¢°ë„ ë–¨ì–´ì§€ë‹ˆ ìŠ¤í‚µ
                        continue

                    # â”€â”€â”€ [D] ê¹Šì´ ê¸°ë°˜ ê±°ë¦¬ ê³„ì‚° â”€â”€â”€
                    z_mm_med = np.median(valid_depth)        # ì¤‘ì•™ê°’ (ë…¸ì´ì¦ˆì— ê°•í•¨)
                    z_meter = z_mm_med / 1000.0              # m ë‹¨ìœ„ë¡œ ë³€í™˜

                    if z_meter <= 0:
                        continue

                    # â”€â”€â”€ [E] ê¹Šì´ ë³€ë™ì„±(ì…ì²´ê°) ê³„ì‚° â”€â”€â”€
                    # ì¤‘ì•™ê°’ì—ì„œ Â±150mm ì´ë‚´ ê°’ë§Œ ì‚¬ìš©í•˜ì—¬ ë°°ê²½ ì˜í–¥ ì¤„ì´ê¸°
                    depth_window = valid_depth[np.abs(valid_depth - z_mm_med) < 150]
                    if depth_window.size < MIN_VALID_DEPTH_PIXELS // 2:
                        depth_window = valid_depth  # ë„ˆë¬´ ì¤„ì–´ë“¤ë©´ ë‹¤ì‹œ ì „ì²´ ì‚¬ìš©

                    depth_std_mm = float(np.std(depth_window))  # mm ë‹¨ìœ„ í‘œì¤€í¸ì°¨

                    # â”€â”€â”€ [F] 3D ì¢Œí‘œ ê³„ì‚° (ì¹´ë©”ë¼ ì¢Œí‘œê³„ ê¸°ì¤€) â”€â”€â”€
                    real_x = (center_x - cx) * z_mm_med / fx / 1000.0
                    real_y = (center_y - cy) * z_mm_med / fy / 1000.0

                    face_info = {
                        "bbox": (x1, y1, x2, y2),
                        "center": (center_x, center_y),
                        "z_meter": z_meter,
                        "z_mm": z_mm_med,
                        "depth_std_mm": depth_std_mm,
                        "real_x": real_x,
                        "real_y": real_y,
                    }

                    # â”€â”€â”€ [G] ê°€ì¥ ê°€ê¹Œìš´ ì–¼êµ´ë§Œ ì„ íƒ â”€â”€â”€
                    if best_face is None or z_meter < best_face["z_meter"]:
                        best_face = face_info

            # â”€â”€â”€ [ê°€ì¥ ê°€ê¹Œìš´ ì–¼êµ´ë§Œ í™”ë©´ì— í‘œì‹œ + í•„í„°ë§/ìŠ¤í‘¸í•‘ íŒì •] â”€â”€â”€
            if best_face is not None:
                x1, y1, x2, y2 = best_face["bbox"]
                center_x, center_y = best_face["center"]
                z_meter = best_face["z_meter"]
                depth_std_mm = best_face["depth_std_mm"]
                real_x = best_face["real_x"]
                real_y = best_face["real_y"]

                # 1ë‹¨ê³„: ê±°ë¦¬ í•„í„°ë§
                in_range = (MIN_DISTANCE <= z_meter <= MAX_DISTANCE)

                # 2ë‹¨ê³„: ì•ˆí‹° ìŠ¤í‘¸í•‘ (ì‹¤ë¬¼/ì‚¬ì§„ êµ¬ë¶„)
                # ê±°ë¦¬ ë²”ìœ„ ì•ˆì— ìˆëŠ” ê²½ìš°ì—ë§Œ ìŠ¤í‘¸í•‘ íŒì • ì˜ë¯¸ê°€ ìˆìŒ
                if in_range:
                    if depth_std_mm < DEPTH_STD_THRESHOLD_MM:
                        # í‰ë©´ì— ê°€ê¹Œì›€ -> ì‚¬ì§„/ëª¨ë‹ˆí„°ì¼ ê°€ëŠ¥ì„± í¼
                        status = "FAIL-FAKE"   # ê±°ë¦¬ OKì§€ë§Œ ì‚¬ì§„ì¼ ê°€ëŠ¥ì„±
                        color = (0, 0, 255)
                        thickness = 2
                        spoof_label = "PHOTO/FLAT"
                    else:
                        status = "PASS-REAL"   # ê±°ë¦¬ OK + ì–¼êµ´ì´ ì…ì²´ì 
                        color = (0, 255, 0)
                        thickness = 3
                        spoof_label = "REAL"
                else:
                    # ê±°ë¦¬ ë²”ìœ„ ë°–ì´ë©´ ìŠ¤í‘¸í•‘ ì—¬ë¶€ì™€ ìƒê´€ì—†ì´ ë¶ˆí•©ê²©
                    status = "FAIL-DIST"
                    color = (0, 0, 255)
                    thickness = 2
                    spoof_label = "OUT_RANGE"

                # â”€â”€â”€ [í™”ë©´ ê·¸ë¦¬ê¸°] â”€â”€â”€
                cv2.rectangle(img_bgr, (x1, y1), (x2, y2), color, thickness)

                # ìƒíƒœ + ê±°ë¦¬ ì •ë³´
                info_status = f"[{status}] Dist: {z_meter:.2f}m"
                cv2.putText(
                    img_bgr,
                    info_status,
                    (x1, y1 - 30),
                    cv2.FONT_HERSHEY_DUPLEX,
                    0.7,
                    color,
                    2
                )

                # ì‹¤ë¬¼/ì‚¬ì§„ íŒì • + ê¹Šì´ í‘œì¤€í¸ì°¨
                info_spoof = f"{spoof_label} | DepthStd: {depth_std_mm:.1f}mm"
                cv2.putText(
                    img_bgr,
                    info_spoof,
                    (x1, y1 - 10),
                    cv2.FONT_HERSHEY_DUPLEX,
                    0.55,
                    color,
                    1
                )

                # ì¢Œí‘œ ì •ë³´
                info_coord = f"X:{real_x:.2f} Y:{real_y:.2f}"
                cv2.putText(
                    img_bgr,
                    info_coord,
                    (x1, y2 + 20),
                    cv2.FONT_HERSHEY_DUPLEX,
                    0.55,
                    color,
                    1
                )

                # ì¤‘ì‹¬ì  í‘œì‹œ
                cv2.circle(img_bgr, (center_x, center_y), 5, color, -1)

            # ìµœì¢… í™”ë©´ ì¶œë ¥
            cv2.imshow("School Access System (Nearest + Anti-Spoof)", img_bgr)

        if cv2.waitKey(1) == 27:  # ESC í‚¤
            break

    k4a.stop()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()
