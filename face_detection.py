import os
import glob

import cv2
import numpy as np
import mediapipe as mp  # ê°€ë³ê³  ë¹ ë¥¸ ì–¼êµ´ ê²€ì¶œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import face_recognition  # ì–¼êµ´ ì„ë² ë”©/ë¹„êµ ë¼ì´ë¸ŒëŸ¬ë¦¬
from pyk4a import PyK4A, Config, ColorResolution, DepthMode, FPS

# â”€â”€â”€ [ì„¤ì •: ê±°ë¦¬ í•„í„°ë§ ë²”ìœ„] â”€â”€â”€
MIN_DISTANCE = 0.3   # m
MAX_DISTANCE = 0.5   # m

# â”€â”€â”€ [ì„¤ì •: ì•ˆí‹° ìŠ¤í‘¸í•‘(ì‹¤ë¬¼ vs ì‚¬ì§„) ì„ê³„ê°’] â”€â”€â”€
DEPTH_STD_THRESHOLD_MM = 15.0    # 15mm (í™˜ê²½ì— ë§ê²Œ íŠœë‹)
MIN_VALID_DEPTH_PIXELS = 80      # ê¹Šì´ íŒ¨ì¹˜ ë‚´ ìµœì†Œ ìœ íš¨ í”½ì…€ ìˆ˜

# â”€â”€â”€ [ì„¤ì •: í•œì–‘ëŒ€ í•™ìƒ ì–¼êµ´ DB í´ë”] â”€â”€â”€
HYU_STUDENTS_DIR = "./hyu_students"   # â˜…â˜… ì—¬ê¸°ë¥¼ ë³¸ì¸ í´ë” ê²½ë¡œë¡œ ë³€ê²½
FACE_MATCH_THRESHOLD = 0.5            # â˜…â˜… ì–¼êµ´ ë§¤ì¹­ ì„ê³„ê°’ (ì‘ì„ìˆ˜ë¡ ì—„ê²©)

# â”€â”€â”€ [ì „ì—­: í•œì–‘ëŒ€ í•™ìƒ ì„ë² ë”© DB] â”€â”€â”€
KNOWN_FACE_ENCODINGS = []
KNOWN_FACE_LABELS = []

# 1. ë¯¸ë””ì–´íŒŒì´í”„(ì–¼êµ´ ê²€ì¶œ AI) ì´ˆê¸°í™”
mp_face_detection = mp.solutions.face_detection
face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.6)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í•œì–‘ëŒ€í•™êµ í•™ìƒ ì–¼êµ´ DB ë¡œë”©
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_hyu_students():
    global KNOWN_FACE_ENCODINGS, KNOWN_FACE_LABELS

    KNOWN_FACE_ENCODINGS = []
    KNOWN_FACE_LABELS = []

    if not os.path.isdir(HYU_STUDENTS_DIR):
        print(f"âš  HYU_STUDENTS_DIRê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {HYU_STUDENTS_DIR}")
        return

    img_paths = glob.glob(os.path.join(HYU_STUDENTS_DIR, "*.*"))

    print(f"ğŸ“‚ í•œì–‘ëŒ€ í•™ìƒ ì‚¬ì§„ ë¡œë”© ì¤‘... (í´ë”: {HYU_STUDENTS_DIR})")

    for img_path in img_paths:
        try:
            img = face_recognition.load_image_file(img_path)
            encodings = face_recognition.face_encodings(img)
            if not encodings:
                print(f"  â¤ ì–¼êµ´ì„ ì°¾ì§€ ëª»í•´ ìŠ¤í‚µ: {img_path}")
                continue

            encoding = encodings[0]
            label = os.path.splitext(os.path.basename(img_path))[0]  # íŒŒì¼ëª…(í™•ì¥ì ì œì™¸)ì„ ë¼ë²¨ë¡œ ì‚¬ìš©
            KNOWN_FACE_ENCODINGS.append(encoding)
            KNOWN_FACE_LABELS.append(label)
            print(f"  âœ… ë“±ë¡: {label}")
        except Exception as e:
            print(f"  âŒ ë¡œë”© ì‹¤íŒ¨: {img_path}, ì—ëŸ¬: {e}")

    print(f"âœ… í•œì–‘ëŒ€ í•™ìƒ DB ë¡œë”© ì™„ë£Œ: {len(KNOWN_FACE_LABELS)}ëª… ë“±ë¡")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í˜„ì¬ ì–¼êµ´ì´ í•œì–‘ëŒ€ í•™ìƒ DBì— ìˆëŠ”ì§€ íŒë‹¨
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def recognize_hyu_student(face_bgr):
    """
    face_bgr: ì–¼êµ´ ë¶€ë¶„ì´ ì˜ë¦° BGR ì´ë¯¸ì§€ (numpy array)
    return: (label or None, best_distance or None)
    """
    if len(KNOWN_FACE_ENCODINGS) == 0:
        return None, None

    # face_recognitionì€ RGBë¥¼ ì‚¬ìš©
    face_rgb = cv2.cvtColor(face_bgr, cv2.COLOR_BGR2RGB)
    encodings = face_recognition.face_encodings(face_rgb)

    if not encodings:
        return None, None

    face_encoding = encodings[0]

    # DBì™€ ëª¨ë“  ê±°ë¦¬ ê³„ì‚°
    distances = face_recognition.face_distance(KNOWN_FACE_ENCODINGS, face_encoding)
    if len(distances) == 0:
        return None, None

    best_idx = np.argmin(distances)
    best_distance = float(distances[best_idx])

    if best_distance < FACE_MATCH_THRESHOLD:
        return KNOWN_FACE_LABELS[best_idx], best_distance
    else:
        return None, best_distance


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë©”ì¸ ë¡œì§
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    # 2. Azure Kinect ì¹´ë©”ë¼ ì„¤ì •
    k4a = PyK4A(
        Config(
            color_resolution=ColorResolution.RES_720P,
            depth_mode=DepthMode.NFOV_UNBINNED,
            camera_fps=FPS.FPS_30,
            synchronized_images_only=True,
        )
    )
    
    try:
        k4a.start()
        print(f"âœ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ (ë©€í‹° ì–¼êµ´ + ì•ˆí‹°ìŠ¤í‘¸í•‘ + HYU ì¸ì¦)")
        print(f"ğŸ¯ ìœ íš¨ ê±°ë¦¬ ì„¤ì •: {MIN_DISTANCE}m ~ {MAX_DISTANCE}m")
        print(f"ğŸ›¡ ì•ˆí‹°ìŠ¤í‘¸í•‘ ê¹Šì´ í‘œì¤€í¸ì°¨ ì„ê³„ê°’: {DEPTH_STD_THRESHOLD_MM} mm")
        print(f"ğŸ“ HYU ì–¼êµ´ ë§¤ì¹­ ì„ê³„ê°’: {FACE_MATCH_THRESHOLD}")
    except Exception as e:
        print(f"âŒ ì¹´ë©”ë¼ ì—°ê²° ì‹¤íŒ¨: {e}")
        return

    # ì¢Œí‘œ ê³„ì‚°ìš© íŒŒë¼ë¯¸í„° (color ì¹´ë©”ë¼ ë‚´ì°¸ìˆ˜)
    intrinsics = k4a.calibration.get_camera_matrix(1)
    fx, fy = intrinsics[0, 0], intrinsics[1, 1]
    cx, cy = intrinsics[0, 2], intrinsics[1, 2]

    while True:
        capture = k4a.get_capture()
        
        if capture.color is not None and capture.depth is not None:
            # 1. ì´ë¯¸ì§€ ì²˜ë¦¬ (MediaPipeëŠ” RGBë¥¼ ì‚¬ìš©)
            img_bgr = capture.color[:, :, :3].copy()  # ì“°ê¸° ê°€ëŠ¥í•˜ë„ë¡ ë³µì‚¬
            img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
            
            # 2. Depth ë§µ (ì´ë¯¸ colorì— ì •ë ¬ëœ ê¹Šì´)
            transformed_depth = capture.transformed_depth

            # 3. ì–¼êµ´ ê²€ì¶œ ìˆ˜í–‰
            results = face_detection.process(img_rgb)

            best_face = None  # ê°€ì¥ ê°€ê¹Œìš´ ì–¼êµ´ ì •ë³´ ì €ì¥ìš©

            if results.detections:
                h, w, _ = img_bgr.shape

                for detection in results.detections:
                    # â”€â”€â”€ [A] Bounding Box ì¢Œí‘œ ê³„ì‚° â”€â”€â”€
                    bboxC = detection.location_data.relative_bounding_box
                    x = int(bboxC.xmin * w)
                    y = int(bboxC.ymin * h)
                    box_w = int(bboxC.width * w)
                    box_h = int(bboxC.height * h)

                    # ë°•ìŠ¤ ì˜ì—­ í´ë¨í•‘
                    x1 = max(0, x)
                    y1 = max(0, y)
                    x2 = min(w - 1, x + box_w)
                    y2 = min(h - 1, y + box_h)

                    if x2 <= x1 or y2 <= y1:
                        continue

                    # â”€â”€â”€ [B] ì¤‘ì‹¬ì  ê³„ì‚° â”€â”€â”€
                    center_x = (x1 + x2) // 2
                    center_y = (y1 + y2) // 2

                    # â”€â”€â”€ [C] ê¹Šì´ íŒ¨ì¹˜ ì¶”ì¶œ (ì–¼êµ´ ë°•ìŠ¤ ì¤‘ì•™ 40%) â”€â”€â”€
                    patch_w = int((x2 - x1) * 0.4)
                    patch_h = int((y2 - y1) * 0.4)

                    patch_cx = center_x
                    patch_cy = center_y

                    px1 = max(0, patch_cx - patch_w // 2)
                    px2 = min(w - 1, patch_cx + patch_w // 2)
                    py1 = max(0, patch_cy - patch_h // 2)
                    py2 = min(h - 1, patch_cy + patch_h // 2)

                    if px2 <= px1 or py2 <= py1:
                        continue

                    depth_patch = transformed_depth[py1:py2+1, px1:px2+1]
                    valid_depth = depth_patch[depth_patch > 0]  # 0ì€ ë¯¸ì¸¡ì •ê°’ì´ë¯€ë¡œ ì œì™¸

                    if valid_depth.size < MIN_VALID_DEPTH_PIXELS:
                        continue

                    # â”€â”€â”€ [D] ê¹Šì´ ê¸°ë°˜ ê±°ë¦¬ ê³„ì‚° â”€â”€â”€
                    z_mm_med = np.median(valid_depth)
                    z_meter = z_mm_med / 1000.0

                    if z_meter <= 0:
                        continue

                    # â”€â”€â”€ [E] ê¹Šì´ ë³€ë™ì„±(ì…ì²´ê°) ê³„ì‚° â”€â”€â”€
                    depth_window = valid_depth[np.abs(valid_depth - z_mm_med) < 150]
                    if depth_window.size < MIN_VALID_DEPTH_PIXELS // 2:
                        depth_window = valid_depth

                    depth_std_mm = float(np.std(depth_window))

                    # â”€â”€â”€ [F] 3D ì¢Œí‘œ ê³„ì‚° â”€â”€â”€
                    real_x = (center_x - cx) * z_mm_med / fx / 1000.0
                    real_y = (center_y - cy) * z_mm_med / fy / 1000.0

                    face_info = {
                        "bbox": (x1, y1, x2, y2),
                        "center": (center_x, center_y),
                        "z_meter": z_meter,
                        "z_mm": z_mm_med,
                        "depth_std_mm": depth_std_mm,
                        "real_x": real_x,
                        "real_y": real_y,
                    }

                    # â”€â”€â”€ [G] ê°€ì¥ ê°€ê¹Œìš´ ì–¼êµ´ë§Œ ì„ íƒ â”€â”€â”€
                    if best_face is None or z_meter < best_face["z_meter"]:
                        best_face = face_info

            # â”€â”€â”€ [ê°€ì¥ ê°€ê¹Œìš´ ì–¼êµ´ë§Œ í™”ë©´ì— í‘œì‹œ + ê±°ë¦¬/ìŠ¤í‘¸í•‘/HYU íŒì •] â”€â”€â”€
            if best_face is not None:
                x1, y1, x2, y2 = best_face["bbox"]
                center_x, center_y = best_face["center"]
                z_meter = best_face["z_meter"]
                depth_std_mm = best_face["depth_std_mm"]
                real_x = best_face["real_x"]
                real_y = best_face["real_y"]

                # 1ë‹¨ê³„: ê±°ë¦¬ í•„í„°ë§
                in_range = (MIN_DISTANCE <= z_meter <= MAX_DISTANCE)

                # ê¸°ë³¸ê°’
                status = "FAIL"
                spoof_label = "UNKNOWN"
                hyu_label = None
                face_dist = None

                color = (0, 0, 255)
                thickness = 2

                if in_range:
                    # 2ë‹¨ê³„: ì•ˆí‹° ìŠ¤í‘¸í•‘ (ì‹¤ë¬¼/ì‚¬ì§„)
                    if depth_std_mm < DEPTH_STD_THRESHOLD_MM:
                        status = "FAIL-FAKE"
                        spoof_label = "PHOTO/FLAT"
                    else:
                        # 3ë‹¨ê³„: HYU ì–¼êµ´ ë§¤ì¹­
                        face_roi = img_bgr[y1:y2, x1:x2]
                        hyu_label, face_dist = recognize_hyu_student(face_roi)

                        if hyu_label is not None:
                            status = "PASS-HYU"
                            spoof_label = f"REAL-HYU ({hyu_label})"
                            color = (0, 255, 0)
                            thickness = 3
                        else:
                            status = "FAIL-NOT-HYU"
                            spoof_label = "REAL-NOT_IN_DB"
                else:
                    status = "FAIL-DIST"
                    spoof_label = "OUT_RANGE"

                # â”€â”€â”€ [í™”ë©´ ê·¸ë¦¬ê¸°] â”€â”€â”€
                cv2.rectangle(img_bgr, (x1, y1), (x2, y2), color, thickness)

                # ìƒíƒœ + ê±°ë¦¬
                info_status = f"[{status}] Dist: {z_meter:.2f}m"
                cv2.putText(
                    img_bgr,
                    info_status,
                    (x1, y1 - 35),
                    cv2.FONT_HERSHEY_DUPLEX,
                    0.7,
                    color,
                    2
                )

                # ìŠ¤í‘¸í•‘/HYU ì •ë³´ + ê¹Šì´ í‘œì¤€í¸ì°¨
                if face_dist is not None:
                    spoof_text = f"{spoof_label} | DepthStd: {depth_std_mm:.1f}mm | FaceDist: {face_dist:.2f}"
                else:
                    spoof_text = f"{spoof_label} | DepthStd: {depth_std_mm:.1f}mm"

                cv2.putText(
                    img_bgr,
                    spoof_text,
                    (x1, y1 - 12),
                    cv2.FONT_HERSHEY_DUPLEX,
                    0.55,
                    color,
                    1
                )

                # ì¢Œí‘œ ì •ë³´
                info_coord = f"X:{real_x:.2f} Y:{real_y:.2f}"
                cv2.putText(
                    img_bgr,
                    info_coord,
                    (x1, y2 + 20),
                    cv2.FONT_HERSHEY_DUPLEX,
                    0.55,
                    color,
                    1
                )

                # ì¤‘ì‹¬ì  í‘œì‹œ
                cv2.circle(img_bgr, (center_x, center_y), 5, color, -1)

            # ìµœì¢… í™”ë©´ ì¶œë ¥
            cv2.imshow("School Access System (HYU + Anti-Spoof)", img_bgr)

        if cv2.waitKey(1) == 27:  # ESC í‚¤
            break

    k4a.stop()
    cv2.destroyAllWindows()


if __name__ == "__main__":
    # í•œì–‘ëŒ€ í•™ìƒ DB ë¨¼ì € ë¡œë”©
    load_hyu_students()
    main()
