import cv2
import numpy as np
import face_recognition
from PIL import Image
from pyk4a import PyK4A, Config, ColorResolution, DepthMode, FPS

# â”€â”€â”€ [1. ì„¤ì •] â”€â”€â”€
MIN_DISTANCE = 0.3
MAX_DISTANCE = 0.5
STUDENT_IMAGE_FILE = "student.jpg"
STUDENT_NAME = "Jeong Hee-chan"

# â”€â”€â”€ [2. í•™ìƒ ë°ì´í„° ë¡œë”© (ë©”ëª¨ë¦¬ ì •ë ¬ ì¶”ê°€)] â”€â”€â”€
print("ğŸ”„ í•™ìƒ ë°ì´í„° ë¡œë”© ì¤‘...")

try:
    # 1. Pillowë¡œ ì´ë¯¸ì§€ ì—´ê¸°
    pil_image = Image.open(STUDENT_IMAGE_FILE)
    
    # 2. RGBë¡œ ë³€í™˜
    pil_image = pil_image.convert("RGB")
    
    # 3. Numpy ë°°ì—´ë¡œ ë³€í™˜
    student_image_np = np.array(pil_image)
    
    # [í•µì‹¬ ìˆ˜ì • 1] ë°ì´í„° íƒ€ì… ê°•ì œ (uint8)
    student_image_np = student_image_np.astype(np.uint8)

    # [í•µì‹¬ ìˆ˜ì • 2] â­ ë©”ëª¨ë¦¬ ì—°ì†ì„± ê°•ì œ ì •ë ¬ (Contiguous Array) â­
    # ì´ ì¤„ì´ ì—†ìœ¼ë©´ dlibì´ "Unsupported image type" ì—ëŸ¬ë¥¼ ë‚¼ ìˆ˜ ìˆìŒ
    student_image_np = np.ascontiguousarray(student_image_np)

    # ë””ë²„ê¹… ì •ë³´ ì¶œë ¥
    print(f"ğŸ” ì´ë¯¸ì§€ ì§„ë‹¨: í¬ê¸°={student_image_np.shape}, íƒ€ì…={student_image_np.dtype}")
    print(f"ğŸ” ë©”ëª¨ë¦¬ ì—°ì†ì„± í™•ì¸: {student_image_np.flags['C_CONTIGUOUS']}")

    # 4. ì–¼êµ´ íŠ¹ì§• ì¶”ì¶œ
    student_encodings = face_recognition.face_encodings(student_image_np)
    
    if len(student_encodings) == 0:
        print("âŒ ì˜¤ë¥˜: ì‚¬ì§„ì—ì„œ ì–¼êµ´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ìº¡ì²˜í•´ì£¼ì„¸ìš”.")
        exit()
        
    student_encoding = student_encodings[0]
    
    known_face_encodings = [student_encoding]
    known_face_names = [STUDENT_NAME]
    print(f"âœ… í•™ìƒ ë“±ë¡ ì™„ë£Œ: {STUDENT_NAME}")

except Exception as e:
    print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
    exit()

def main():
    # â”€â”€â”€ [3. Azure Kinect ì„¤ì •] â”€â”€â”€
    k4a = PyK4A(
        Config(
            color_resolution=ColorResolution.RES_720P,
            depth_mode=DepthMode.NFOV_UNBINNED,
            camera_fps=FPS.FPS_30,
            synchronized_images_only=True,
        )
    )
    
    try:
        k4a.start()
        print(f"âœ… ì‹œìŠ¤í…œ ì‹œì‘! (ìœ íš¨ ê±°ë¦¬: {MIN_DISTANCE}m ~ {MAX_DISTANCE}m)")
    except Exception as e:
        print(f"âŒ ì¹´ë©”ë¼ ì—°ê²° ì‹¤íŒ¨: {e}")
        return

    intrinsics = k4a.calibration.get_camera_matrix(1)
    fx, fy = intrinsics[0, 0], intrinsics[1, 1]
    cx, cy = intrinsics[0, 2], intrinsics[1, 2]

    while True:
        capture = k4a.get_capture()
        
        if capture.color is not None and capture.depth is not None:
            # ì‹¤ì‹œê°„ ì˜ìƒë„ ë©”ëª¨ë¦¬ ì •ë ¬í•´ì„œ ë³µì‚¬
            img_bgr = np.ascontiguousarray(capture.color[:, :, :3])
            img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
            transformed_depth = capture.transformed_depth

            face_locations = face_recognition.face_locations(img_rgb)
            face_encodings = face_recognition.face_encodings(img_rgb, face_locations)

            for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):
                
                # â‘  ì‹ ì› í™•ì¸
                matches = face_recognition.compare_faces(known_face_encodings, face_encoding, tolerance=0.5)
                name = "Unknown"
                
                if True in matches:
                    first_match_index = matches.index(True)
                    name = known_face_names[first_match_index]

                # â‘¡ ê±°ë¦¬ ì¸¡ì •
                center_x = (left + right) // 2
                center_y = (top + bottom) // 2
                
                h, w, _ = img_bgr.shape
                center_x = max(0, min(center_x, w - 1))
                center_y = max(0, min(center_y, h - 1))

                z_mm = transformed_depth[center_y, center_x]
                z_meter = z_mm / 1000.0

                if z_meter == 0: continue

                real_x = (center_x - cx) * z_mm / fx / 1000.0
                real_y = (center_y - cy) * z_mm / fy / 1000.0

                # â‘¢ ìµœì¢… íŒì •
                is_authenticated = (name == STUDENT_NAME)
                is_valid_distance = (MIN_DISTANCE <= z_meter <= MAX_DISTANCE)

                if is_authenticated and is_valid_distance:
                    color = (0, 255, 0)
                    status_text = "ACCESS GRANTED"
                    box_thick = 3
                else:
                    color = (0, 0, 255)
                    box_thick = 2
                    if not is_authenticated:
                        status_text = "DENIED (Unknown)"
                    else:
                        status_text = "Too Far/Close"

                cv2.rectangle(img_bgr, (left, top), (right, bottom), color, box_thick)
                cv2.rectangle(img_bgr, (left, top - 60), (right, top), color, cv2.FILLED)
                cv2.putText(img_bgr, name, (left + 6, top - 36), cv2.FONT_HERSHEY_DUPLEX, 0.7, (255, 255, 255), 1)
                cv2.putText(img_bgr, status_text, (left + 6, top - 6), cv2.FONT_HERSHEY_DUPLEX, 0.5, (255, 255, 255), 1)
                cv2.putText(img_bgr, f"Dist: {z_meter:.2f}m", (left, bottom + 25), cv2.FONT_HERSHEY_DUPLEX, 0.7, color, 1)

            cv2.imshow("School Access System", img_bgr)

        if cv2.waitKey(1) == 27:
            break

    k4a.stop()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()


âŒ ì˜¤ë¥˜ ë°œìƒ: Unsupported image type, must be 8bit gray or RGB image.
